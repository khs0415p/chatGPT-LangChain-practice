{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai (from -r requirements.txt (line 1))\n",
      "  Downloading openai-1.10.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting langchain (from -r requirements.txt (line 2))\n",
      "  Downloading langchain-0.1.4-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai->-r requirements.txt (line 1))\n",
      "  Downloading anyio-4.2.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai->-r requirements.txt (line 1))\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai->-r requirements.txt (line 1))\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai->-r requirements.txt (line 1))\n",
      "  Downloading pydantic-2.5.3-py3-none-any.whl.metadata (65 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sniffio (from openai->-r requirements.txt (line 1))\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting tqdm>4 (from openai->-r requirements.txt (line 1))\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from openai->-r requirements.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from langchain->-r requirements.txt (line 2)) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain->-r requirements.txt (line 2))\n",
      "  Downloading SQLAlchemy-2.0.25-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain->-r requirements.txt (line 2))\n",
      "  Downloading aiohttp-3.9.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain->-r requirements.txt (line 2))\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain->-r requirements.txt (line 2))\n",
      "  Downloading dataclasses_json-0.6.3-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain->-r requirements.txt (line 2))\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.14 (from langchain->-r requirements.txt (line 2))\n",
      "  Downloading langchain_community-0.0.16-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<0.2,>=0.1.16 (from langchain->-r requirements.txt (line 2))\n",
      "  Downloading langchain_core-0.1.16-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langsmith<0.1,>=0.0.83 (from langchain->-r requirements.txt (line 2))\n",
      "  Downloading langsmith-0.0.84-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from langchain->-r requirements.txt (line 2)) (1.26.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from langchain->-r requirements.txt (line 2)) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain->-r requirements.txt (line 2))\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2))\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2))\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2))\n",
      "  Downloading frozenlist-1.4.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2))\n",
      "  Downloading multidict-6.0.4-cp39-cp39-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2))\n",
      "  Downloading yarl-1.9.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 1)) (1.1.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 2))\n",
      "  Downloading marshmallow-3.20.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 2))\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: certifi in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (2023.7.22)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 1))\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 1))\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain->-r requirements.txt (line 2))\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1.16->langchain->-r requirements.txt (line 2)) (23.2)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1))\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.14.6 (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1))\n",
      "  Downloading pydantic_core-2.14.6-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (3.3.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (2.0.7)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 2))\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading openai-1.10.0-py3-none-any.whl (225 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.1.4-py3-none-any.whl (803 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.2-cp39-cp39-macosx_11_0_arm64.whl (387 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.8/387.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading anyio-4.2.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.16-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.1.16-py3-none-any.whl (230 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.3/230.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.0.84-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.14.6-cp39-cp39-macosx_11_0_arm64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.25-cp39-cp39-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.4.1-cp39-cp39-macosx_11_0_arm64.whl (53 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.9.4-cp39-cp39-macosx_11_0_arm64.whl (81 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.8/81.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, tenacity, SQLAlchemy, sniffio, pydantic-core, mypy-extensions, multidict, marshmallow, jsonpointer, h11, frozenlist, distro, attrs, async-timeout, annotated-types, yarl, typing-inspect, pydantic, jsonpatch, httpcore, anyio, aiosignal, langsmith, httpx, dataclasses-json, aiohttp, openai, langchain-core, langchain-community, langchain\n",
      "Successfully installed SQLAlchemy-2.0.25 aiohttp-3.9.2 aiosignal-1.3.1 annotated-types-0.6.0 anyio-4.2.0 async-timeout-4.0.3 attrs-23.2.0 dataclasses-json-0.6.3 distro-1.9.0 frozenlist-1.4.1 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.4 langchain-community-0.0.16 langchain-core-0.1.16 langsmith-0.0.84 marshmallow-3.20.2 multidict-6.0.4 mypy-extensions-1.0.0 openai-1.10.0 pydantic-2.5.3 pydantic-core-2.14.6 sniffio-1.3.0 tenacity-8.2.3 tqdm-4.66.1 typing-inspect-0.9.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"API KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Language Model Application\n",
    "\n",
    "### LLMS: 언어모델로부터 응답 얻기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. 이탈리아의 로마\n",
      "2. 프랑스의 낭트르\n",
      "3. 스페인의 바르셀로나\n",
      "4. 그리스의 산토리니\n",
      "5. 미국의 뉴욕\n"
     ]
    }
   ],
   "source": [
    "text = \"파스타를 좋아하는 사람이 갈만한 여행지 5곳은 어디입니까?\"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates: LLMs를 위한 프롬프트 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['음식'],\n",
    "    template=\"{음식}을 좋아하는 사람이 갈만한 여행지 5곳은 어디입니까?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "케익을 좋아하는 사람이 갈만한 여행지 5곳은 어디입니까?\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(음식=\"케익\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. 프랑스, 파리 - 파리는 케익의 고장으로 유명하며, 맛있는 크로와상과 마카롱을 즐길 수 있는 곳으로 유명합니다.\n",
      "\n",
      "2. 호주, 멜버른 - 멜버른은 케익을 대표하는 디저트 카페와 베이커리가 많은 도시로, 차이나타운에서는 유명한 중국식 달고나 케이크를 맛볼 수 있습니다.\n",
      "\n",
      "3. 일본, 오사카 - 오사카는 일본 전통 디저트 중 하나인 담백한 녹차 맛의 모찌와 함께 실망시켜주는 케익도 유명합니다.\n",
      "\n",
      "4. 스위스, 취리히 - 취리히는 스위스의 대표적인 디\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt.format(음식=\"케익\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chains: LLMs와 프롬프트의 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"food\"],\n",
    "    template=\"What are 5 vacation destinations for someone who likes to eat {food}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Hawaii - Known for its tropical fruits such as pineapple, mango, and papaya, Hawaii is the perfect destination for fruit lovers. Visitors can also try exotic fruits like dragon fruit, star fruit, and lychee.\n",
      "\n",
      "2. Thailand - With its bustling markets and street food scene, Thailand offers a wide variety of fresh and delicious fruits such as durian, mango, and pomelo. Visitors can also try unique fruits like snake fruit and longan.\n",
      "\n",
      "3. Costa Rica - This Central American country is a fruit lover's paradise with its abundance of tropical fruits like bananas, pineapples, and passion fruit. Visitors can also try lesser-known fruits like guanabana and mamey sapote.\n",
      "\n",
      "4. Greece - Known for its Mediterranean cuisine, Greece also offers a variety of fruits such as figs, pomegranates, and grapes. Visitors can also enjoy traditional Greek dishes made with fruits, such as baklava and loukoumades.\n",
      "\n",
      "5. California - With its sunny climate and fertile soil, California produces a wide range of fruits such as strawberries, oranges, and avocados. Visitors can also visit farmers' markets and pick their own fruits at local farms.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"fruit\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents: Dynamically call chains based on user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (2.4.2)\n",
      "Requirement already satisfied: requests in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from google-search-results) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from requests->google-search-results) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from requests->google-search-results) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from requests->google-search-results) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from requests->google-search-results) (2023.7.22)\n",
      "Collecting numexpr\n",
      "  Downloading numexpr-2.9.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from numexpr) (1.26.1)\n",
      "Downloading numexpr-2.9.0-cp39-cp39-macosx_11_0_arm64.whl (91 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numexpr\n",
      "Successfully installed numexpr-2.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results\n",
    "!pip install numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in some tools to user\n",
    "# https://python.langchain.com/docs/integrations/tools/\n",
    "# serpapi : 검색 엔진\n",
    "\n",
    "# os.environ[\"SERPAPI_API_KEY\"] = \"...\"\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an agent with\n",
    "# 1. tools\n",
    "# 2. language model\n",
    "# 3. type of agent we want to user\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use a search engine to find the name of the president of Japan and a calculator to find the largest prime number smaller than his age.\n",
      "Action: Search\n",
      "Action Input: \"President of Japan\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'type': 'organic_result', 'title': 'Fumio Kishida', 'source': 'Wikipedia'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the name I found to search for his age.\n",
      "Action: Search\n",
      "Action Input: \"Fumio Kishida age\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m66 years\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use a calculator to find the largest prime number smaller than 66.\n",
      "Action: Calculator\n",
      "Action Input: 66\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 66\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The president of Japan is Fumio Kishida and the largest prime number smaller than his age is 61.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The president of Japan is Fumio Kishida and the largest prime number smaller than his age is 61.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"일본의 대통령은 누구인가요? 그의 나이보다 작으면서 가장 큰 소수는 무엇인가요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory: Add state to chains and agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 안녕!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 안녕하세요! 저는 인공지능입니다. 지금은 한국어를 사용하고 있습니다. 당신은 어떤 언어를 사용하고 계신가요?'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"안녕!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 안녕!\n",
      "AI:  안녕하세요! 저는 인공지능입니다. 지금은 한국어를 사용하고 있습니다. 당신은 어떤 언어를 사용하고 계신가요?\n",
      "Human: 나도 한국어를 사용하고 있고 지금은 대화형 AI를 사용하고 있어.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 정말 멋진 선택이네요! 대화형 AI는 많은 정보를 가지고 있어서 다양한 주제에 대해 대화를 나눌 수 있어요. 무엇에 대해 이야기하고 싶으신가요?'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"나도 한국어를 사용하고 있고 지금은 대화형 AI를 사용하고 있어.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 안녕!\n",
      "AI:  안녕하세요! 저는 인공지능입니다. 지금은 한국어를 사용하고 있습니다. 당신은 어떤 언어를 사용하고 계신가요?\n",
      "Human: 나도 한국어를 사용하고 있고 지금은 대화형 AI를 사용하고 있어.\n",
      "AI:  정말 멋진 선택이네요! 대화형 AI는 많은 정보를 가지고 있어서 다양한 주제에 대해 대화를 나눌 수 있어요. 무엇에 대해 이야기하고 싶으신가요?\n",
      "Human: 내가 했던 첫번째 질문이 뭐야?\n",
      "AI:  죄송해요, 그 질문에 대한 정보는 제가 가지고 있지 않아요. 하지만 제가 알고 있는 것들 중에서 가장 최근에 대화한 주제는 한국어와 대화형 AI에 대한 것이에요.\n",
      "Human: 내가 했던 첫번째 말 기억해?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'  네, 당신이 말한 첫번째 말은 \"안녕!\"이에요. 그리고 제가 당신에게 대답한 첫번째 말은 \"안녕하세요!\"였어요.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"내가 했던 첫번째 말 기억해?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
