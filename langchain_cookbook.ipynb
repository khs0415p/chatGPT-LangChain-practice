{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain ?\n",
    "\n",
    "- LangChain은 언어 모델에 의해 작동하는 애플리케이션을 개발하기 위한 프레임워크이다.\n",
    "\n",
    "**TLDR**\n",
    "\n",
    "LangChain은 아래의 2가지 방법를 통해 AI 모델을 작동하거나 빌드하는 복잡한 과정을 더 쉽게 할 수 있도록 한다.\n",
    "\n",
    "1. Integration - 파일, 다른 애플리케이션이나 API 데이터와 같은 외부 데이터를 쉽게 가져올 수 있다.\n",
    "\n",
    "2. Agency - LLMs가 주어진 환경과 상호 작용하도록 하여 다음 수행할 작업을 결정하는데 도움을 준다.\n",
    "\n",
    "### Why LangChain ?\n",
    "\n",
    "1. Components - LangChain을 사용하면 언어 모델에 작동하기에 필요한 구성요소들을 쉽게 다룰 수 있다.\n",
    "\n",
    "2. Customized Chains - LangChain은 커스터마이징이 가능한 chains라는 컴포넌트를 지원한다.\n",
    "\n",
    "3. Speed - LangChain팀은 매우 빠른 속도로 개발하기 때문에 LLMs의 최신 기능들을 사용할 수 있다.\n",
    "\n",
    "4. Community - 디스코드와 같은 커뮤니티가 활성화 되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = 'YourAPIKey'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Components\n",
    "\n",
    "## Schema - Nuts and Bolts of working with LLMs\n",
    "\n",
    "### Text\n",
    "\n",
    "The natural language way to interact with LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text = \"What day comes after Friday?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Messages\n",
    "\n",
    "- **System** - AI에게 무엇을 해야하는지 알려주는 중요한 배경\n",
    "\n",
    "- **Human** - 사용자의 메세지\n",
    "\n",
    "- **AI** - AI의 메세지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "chat = ChatOpenAI(temperature=.7, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='How about a fresh caprese salad with ripe tomatoes, mozzarella cheese, and basil?')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a nice AI bot that helps a user figure out what to eat in one short sentence\"),\n",
    "        HumanMessage(content=\"I like tomatoes, what should I eat?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You should explore the charming old town and indulge in the delicious local cuisine.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a nice AI bot that helps a user figure out where to travel in one short sentence\"),\n",
    "        HumanMessage(content=\"I like the beaches where should I go?\"),\n",
    "        AIMessage(content=\"You should go to Nice, France\"),\n",
    "        HumanMessage(content=\"What else should I do when I'm there?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documents\n",
    "\n",
    "- 메타데이터와 텍스트를 가지고 있는 객체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"This is my document. It is full of text that I've gathered from other places\", metadata={'my_document_id': 123123, 'my_document_source': 'The LangChain Papers', 'my_document_create_time': 1680013019})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "Document(page_content=\"This is my document. It is full of text that I've gathered from other places\",\n",
    "         metadata={\n",
    "             'my_document_id' : 123123,\n",
    "             'my_document_source' : 'The LangChain Papers',\n",
    "             'my_document_create_time' : 1680013019\n",
    "         })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "#### Language Model\n",
    "[OpenAI models](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nSaturday'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"What day comes after Friday?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the scarecrow win an award? Because he was outstanding in his field! But seriously, to get to New York, you could try walking on water, but it might be easier to just take a plane or a teleportation device if you have one handy. Good luck!')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\n",
    "    [\n",
    "        SystemMessage(content='You are an unhelpful AI bot that makes a joke at whatever the user says'),\n",
    "        HumanMessage(content=\"I would like to go to New York. how should I do this?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Function Calling](https://openai.com/blog/function-calling-and-other-api-updates)\n",
    "\n",
    "GPT는 함수를 실행하지 않고 함수를 실행할 때 필요한 인자를 알려줄 수 있다.  \n",
    "실제 실행은 사용자가 직접 하고, 결과를 다시 GPT에게 제공하여 그 결과를 활용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"location\": \"Boston, MA\"\\n}', 'name': 'get_current_weather'}})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=openai_api_key)\n",
    "\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"72\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)\n",
    "\n",
    "\n",
    "output = chat(messages=[\n",
    "            SystemMessage(content=\"You are an helpful AI bot\"),\n",
    "            HumanMessage(content=\"What's the weather like in Boston right now?\")\n",
    "            ],\n",
    "            functions=[\n",
    "                  {\"name\" : \"get_current_weather\",\n",
    "                   \"description\" : \"Get the current weather in a given location\",\n",
    "                   \"parameters\": {\n",
    "                       \"type\": \"object\",\n",
    "                       \"properties\": {\n",
    "                           \"location\": {\n",
    "                               \"type\" : \"string\",\n",
    "                               \"description\" : \"The city and state, e.g, San Francisco, CA\"\n",
    "                           },\n",
    "                           \"unit\" : {\n",
    "                               \"type\" : \"string\",\n",
    "                               \"enum\" : [\"celsius\", \"fahrenheit\"]\n",
    "                           }\n",
    "                       },\n",
    "                       \"required\" : [\"location\"]\n",
    "                       }\n",
    "                   }\n",
    "            ]\n",
    "            )\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Embedding Model\n",
    "\n",
    "텍스트를 벡터로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.5.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2023.12.25-cp39-cp39-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
      "Downloading tiktoken-0.5.2-cp39-cp39-macosx_11_0_arm64.whl (955 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m955.6/955.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp39-cp39-macosx_11_0_arm64.whl (291 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.0/291.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, tiktoken\n",
      "Successfully installed regex-2023.12.25 tiktoken-0.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hi! It's time for the beach\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding is length 1536\n",
      "Here's a sample: [-0.00019600906371495047, -0.0031846734422911363, -0.0007734206914647714, -0.019472001962491232, -0.015092319017854244]...\n"
     ]
    }
   ],
   "source": [
    "text_embedding = embeddings.embed_query(text)\n",
    "print(f\"Embedding is length {len(text_embedding)}\")\n",
    "print(f\"Here's a sample: {text_embedding[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts - Text generally used as instructions to your model\n",
    "\n",
    "\n",
    "#### Prompt\n",
    "\n",
    "모델에 전달할 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI( openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The statement is incorrect because it skips over Tuesday and jumps directly from Monday to Wednesday.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Today is Monday, tomorrow is Wednesday.\n",
    "\n",
    "Waht is wrong with that statement?\n",
    "\"\"\"\n",
    "\n",
    "print(llm(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Prompt: \n",
      "I really want to travel to Rome. what should I do there?\n",
      "\n",
      "Respond in one short sentence\n",
      "\n",
      "-------------------\n",
      "LLM Output: \n",
      "Visit famous historical sites, try authentic Italian food, and immerse yourself in the vibrant culture.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "llm = OpenAI(openai_api_key=openai_api_key)\n",
    "template = \"\"\"\n",
    "I really want to travel to {localtion}. what should I do there?\n",
    "\n",
    "Respond in one short sentence\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['localtion'],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "final_prompt = prompt.format(localtion='Rome')\n",
    "\n",
    "print(f\"Final Prompt: {final_prompt}\")\n",
    "print('-------------------')\n",
    "print(f\"LLM Output: {llm(final_prompt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Example Selectors](https://python.langchain.com/docs/modules/model_io/prompts/example_selectors/)\n",
    "\n",
    "상황에 맞는 정보를 프롬프트에 동적으로 배치할 수 있는 작업을 방법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.7.4-cp39-cp39-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(openai_api_key=openai_api_key)\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=['input', 'output'],\n",
    "    template=\"Example Input: {input}\\nExample Output: {output}\"\n",
    ")\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"pirate\", \"output\": \"ship\"},\n",
    "    {\"input\": \"pilot\", \"output\": \"plane\"},\n",
    "    {\"input\": \"driver\", \"output\": \"car\"},\n",
    "    {\"input\": \"tree\", \"output\": \"ground\"},\n",
    "    {\"input\": \"bird\", \"output\": \"nest\"},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # 예제 리스트\n",
    "    examples,\n",
    "    # 벡터화를 하기 위한 모델\n",
    "    OpenAIEmbeddings(openai_api_key=openai_api_key),\n",
    "    # 벡터를 저장하고 유사도 검색을 할 수 있도록 하는 벡터 저장소\n",
    "    FAISS,\n",
    "    # 생성할 예제 수\n",
    "    k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    \n",
    "    prefix=\"Give the location an item is usually found in\",\n",
    "    suffix=\"Input: {noun}\\nOutput:\",\n",
    "    \n",
    "    input_variables=[\"noun\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the location an item is usually found in\n",
      "\n",
      "Example Input: tree\n",
      "Example Output: ground\n",
      "\n",
      "Example Input: bird\n",
      "Example Output: nest\n",
      "\n",
      "Input: plant\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "my_noun = \"plant\"\n",
    "\n",
    "print(similar_prompt.format(noun=my_noun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ground'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(similar_prompt.format(noun=my_noun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output Parsers\n",
    "\n",
    "구조화된 출력을 원할 때 유용한 방법 - [docs](https://python.langchain.com/docs/modules/model_io/output_parsers)\n",
    "\n",
    "1. Format Instructions - 원하는 출력을 LLM에 알려주는 자동 생성 프롬프트\n",
    "\n",
    "2. Parser - 모델의 텍스트 출력을 원하는 구조로 추출하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 응답 구성\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"bad_string\", description=\"This a poorly formatted user input string\"),\n",
    "    ResponseSchema(name=\"good_string\", description=\"This is your response, a reformatted response\")\n",
    "]\n",
    "\n",
    "# 출력 구성\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"bad_string\": string  // This a poorly formatted user input string\n",
      "\t\"good_string\": string  // This is your response, a reformatted response\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a poorly formatted string from a user.\n",
      "Reformat it and make sure all the words are spelled correctly\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"bad_string\": string  // This a poorly formatted user input string\n",
      "\t\"good_string\": string  // This is your response, a reformatted response\n",
      "}\n",
      "```\n",
      "\n",
      "% USER INPUT %\n",
      "welcom to califonya!\n",
      "\n",
      "YOUR RESPONSE:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "You will be given a poorly formatted string from a user.\n",
    "Reformat it and make sure all the words are spelled correctly\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "% USER INPUT %\n",
    "{user_input}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"user_input\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    "    template=template\n",
    ")\n",
    "\n",
    "promptValue = prompt.format(user_input=\"welcom to califonya!\")\n",
    "print(promptValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"bad_string\": \"welcom to califonya!\"\n",
      "\t\"good_string\": \"Welcome to California!\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "llm_output = llm(promptValue)\n",
    "print(llm_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document Loaders\n",
    ": PDF, HTML, Text, Markdown, Json, CSV 파일 외에도 다양한 종류의 로컬 파일들과 클라우드 드라이브의 파일들을 읽을 수 있는[ Document loader]((https://python.langchain.com/docs/modules/data_connection/document_loaders.html))들이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.3 soupsieve-2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import HNLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HackerNews**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = HNLoader(\"https://news.ycombinator.com/item?id=34422627\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 76 comments\n",
      "Here's a sample: \n",
      "\n",
      "Ozzie_osman on Jan 18, 2023  \n",
      "             | next [–] \n",
      "\n",
      "LangChain is awesome. For people not sure what it's doing, large language models (LLMs) are veOzzie_osman on Jan 18, 2023  \n",
      "             | parent | next [–] \n",
      "\n",
      "Also, another library to check out is GPT Index (https://github.com/jerryjliu/gpt_ind\n"
     ]
    }
   ],
   "source": [
    "print(f\"Found {len(data)} comments\")\n",
    "print(f\"Here's a sample: \\n\\n{''.join([x.page_content[:150] for x in data[:2]])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**URLs and webpages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured\n",
      "  Downloading unstructured-0.12.3-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting chardet (from unstructured)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting filetype (from unstructured)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: lxml in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from unstructured) (4.9.3)\n",
      "Collecting nltk (from unstructured)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m808.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting tabulate (from unstructured)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: requests in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from unstructured) (4.12.3)\n",
      "Collecting emoji (from unstructured)\n",
      "  Downloading emoji-2.10.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: dataclasses-json in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from unstructured) (0.6.3)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Downloading python_iso639-2024.1.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from unstructured) (1.26.1)\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Downloading rapidfuzz-3.6.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting backoff (from unstructured)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: typing-extensions in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from unstructured) (4.8.0)\n",
      "Collecting unstructured-client>=0.15.1 (from unstructured)\n",
      "  Downloading unstructured_client-0.16.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting wrapt (from unstructured)\n",
      "  Downloading wrapt-1.16.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from unstructured-client>=0.15.1->unstructured) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer>=3.2.0 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from unstructured-client>=0.15.1->unstructured) (3.3.1)\n",
      "Requirement already satisfied: idna>=3.4 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from unstructured-client>=0.15.1->unstructured) (3.4)\n",
      "Collecting jsonpath-python>=1.0.6 (from unstructured-client>=0.15.1->unstructured)\n",
      "  Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: marshmallow>=3.19.0 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from unstructured-client>=0.15.1->unstructured) (3.20.2)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from unstructured-client>=0.15.1->unstructured) (1.0.0)\n",
      "Requirement already satisfied: packaging>=23.1 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from unstructured-client>=0.15.1->unstructured) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from unstructured-client>=0.15.1->unstructured) (2.8.2)\n",
      "Requirement already satisfied: six>=1.16.0 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from unstructured-client>=0.15.1->unstructured) (1.16.0)\n",
      "Requirement already satisfied: typing-inspect>=0.9.0 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from unstructured-client>=0.15.1->unstructured) (0.9.0)\n",
      "Requirement already satisfied: urllib3>=1.26.18 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from unstructured-client>=0.15.1->unstructured) (2.0.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Requirement already satisfied: click in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from nltk->unstructured) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from nltk->unstructured) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from nltk->unstructured) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /Users/khs/anaconda3/envs/pytorch-nlp/lib/python3.9/site-packages (from nltk->unstructured) (4.66.1)\n",
      "Downloading unstructured-0.12.3-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading unstructured_client-0.16.0-py3-none-any.whl (20 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading emoji-2.10.0-py2.py3-none-any.whl (457 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.9/457.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_iso639-2024.1.2-py3-none-any.whl (274 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rapidfuzz-3.6.1-cp39-cp39-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp39-cp39-macosx_11_0_arm64.whl (38 kB)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=16050f587184969a841dd95615978c0a8b5586465d2083602e84030af85d10af\n",
      "  Stored in directory: /Users/khs/Library/Caches/pip/wheels/d1/c1/d9/7e068de779d863bc8f8fc9467d85e25cfe47fa5051fff1a1bb\n",
      "Successfully built langdetect\n",
      "Installing collected packages: filetype, wrapt, tabulate, rapidfuzz, python-magic, python-iso639, nltk, langdetect, jsonpath-python, emoji, chardet, backoff, unstructured-client, unstructured\n",
      "Successfully installed backoff-2.2.1 chardet-5.2.0 emoji-2.10.0 filetype-1.2.0 jsonpath-python-1.0.6 langdetect-1.0.9 nltk-3.8.1 python-iso639-2024.1.2 python-magic-0.4.27 rapidfuzz-3.6.1 tabulate-0.9.0 unstructured-0.12.3 unstructured-client-0.16.0 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New: Superlinear Returns | How to Do Great Work Want to start a startup? Get funded by Y Combinator . © mmxxiii pg'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "urls = [\n",
    "    \"http://www.paulgraham.com/\"\n",
    "]\n",
    "\n",
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "data = loader.load()\n",
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Splitters\n",
    ": 긴 텍스트들을 편리하게 제어할 수 있는 기능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document\n"
     ]
    }
   ],
   "source": [
    "with open(\"./long_doc.txt\") as f:\n",
    "    data = f.read()\n",
    "    \n",
    "print(f\"You have {len([data])} document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 150,\n",
    "    chunk_overlap = 20,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You Have 14 documents.\n"
     ]
    }
   ],
   "source": [
    "print(f\"You Have {len(texts)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview:\n",
      "this is very long document.\n",
      "this is very long document.\n",
      "this is very long document.\n",
      "this is very long document.this is very long document. \n",
      "\n",
      "this is very long document.this is very long document.\n",
      "this is very long document.this is very long document.this is very long document.\n"
     ]
    }
   ],
   "source": [
    "print(\"Preview:\")\n",
    "print(texts[0].page_content, '\\n')\n",
    "print(texts[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrievers\n",
    ": LLMs와 문서들을 연결할 수 있는 기능  \n",
    ": VectoreStoreRetriever가 가장 많이 사용되고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "loaders = TextLoader('./long_doc.txt')\n",
    "documents = loaders.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text splitter 준비\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "\n",
    "# doc 분할\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# 임베딩 모델 준비\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "# 텍스트 임베딩\n",
    "db = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever 초기화\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x291898400>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"I have a long stick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is very long document.\n",
      "\n",
      "is very long document.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n\".join([x.page_content[:50] for x in docs[:2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VectorStores\n",
    ": 벡터를 저장하는 데이터베이스  \n",
    ": **pinecone**, **weaviate**가 가장 유명하다.[참고](https://github.com/openai/chatgpt-retrieval-plugin#choosing-a-vector-database)  \n",
    ": **chroma**, **faiss**는 로컬에서 개발하기 편리하다.\n",
    "\n",
    "개념적으로 임베딩벡터와 메타데이터로 이루어진 테이블이라고 생각할 수 있다.\n",
    "\n",
    "|Embedding|Metadata|\n",
    "|:--:|:--:|\n",
    "|[-0.112..., 0.4432...]|{'date': '1/2/3'...}|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "loader = TextLoader('./long_doc.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=50)\n",
    "\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 22 documents\n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(texts)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list = embeddings.embed_documents([text.page_content for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 22 embeddings\n",
      "Here's a sample of one: [-0.005622338760664389, 0.009526740406156697, -0.003897611605683349]...\n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(embedding_list)} embeddings\")\n",
    "print (f\"Here's a sample of one: {embedding_list[0][:3]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory\n",
    ": LLMs가 정보를 기억할 수 있도록 돕는 기능 [Memory](https://python.langchain.com/docs/modules/memory/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "history.add_ai_message(\"hi!\")\n",
    "\n",
    "history.add_user_message(\"what is the capital of france?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='hi!'),\n",
       " HumanMessage(content='what is the capital of france?')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_response = chat(history.messages)\n",
    "ai_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='hi!'),\n",
       " HumanMessage(content='what is the capital of france?'),\n",
       " AIMessage(content='The capital of France is Paris.')]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.add_ai_message(ai_response.content)\n",
    "history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Chains](https://python.langchain.com/docs/modules/chains)\n",
    "\n",
    ": 다양한 LLM을 호출하고 작업을 결합하는 기능\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Simple Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "llm = OpenAI(temperature=1, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Your job is to come up with a classic dish from the area that the users suggests.\n",
    "% USER LOCATION\n",
    "{user_location}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"user_location\"], template=template)\n",
    "\n",
    "location_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Given a meal, give a short and simple recipe on how to make that dish at home.\n",
    "% MEAL\n",
    "{user_meal}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"user_meal\"], template=template)\n",
    "\n",
    "meal_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain = SimpleSequentialChain(chains=[location_chain, meal_chain], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mFor Rome, a classic dish that comes to mind is Spaghetti alla Carbonara. This pasta dish is made with spaghetti, pancetta or guanciale (cured pork cheek), eggs, pecorino romano cheese, and black pepper. The eggs and cheese create a creamy and rich sauce that pairs perfectly with the salty pancetta. Spaghetti alla Carbonara is a staple in Roman cuisine and is loved by both locals and tourists. It's a simple yet delicious dish that represents the flavors and traditions of Rome. \u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mTo make Spaghetti alla Carbonara at home, start by bringing a pot of salted water to a boil and cooking spaghetti according to package instructions. While the pasta is cooking, heat a large skillet over medium high heat and add in diced pancetta or guanciale. Cook until crispy, then remove from the pan and set aside. In a separate bowl, whisk together eggs, grated pecorino romano cheese, and black pepper. Once the pasta is al dente, drain and add it directly to the skillet with the pancetta. Turn off the heat, then pour in the egg and cheese mixture, tossing the pasta quickly to coat. The heat from the pasta will cook the eggs and create a creamy sauce. Serve hot with additional grated cheese and black pepper on top. Enjoy your homemade Spaghetti alla Carbonara, just like they would in Rome!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "review = overall_chain.run(\"Rome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Summarization Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"[디지털투데이 AI리포터] 오픈AI의 인공지능(AI) 챗봇인 챗GPT가 사용자의 로그인 정보와 개인 정보를 유출했다는 주장이 제기됐다고 30일 IT매체 아스테크니카가 전했다. \n",
      "\n",
      "정보 유출 피해를 입었다고 주장하는 제보자가 제출한 스크린샷에는 약국 처방약 포털의 직원이 사용하는 지원 시스템에 연결된 제보자 이름과 비밀번호가 포함돼 있었다. 이 외에도 앱의 이름과 문제가 발생한 스토어 번호 등이 포함돼 있는 것이 나타났다. \n",
      "\n",
      "이에 대해 제보자는 \"이건 정말 말도 안 되고 끔찍한 일\"이라며 비난했다. 제보자는 \"애초에 챗GPT의 시스템이 얼마나 엉망으로 만들어 진 건가\"라며 우려를 제기했다.\n",
      "\n",
      "이와 같은 사례는 AI 서비스에서 개인 정보를 최대한 배제해야 한다는 점을 상기시킨다. 앞서 2023년 3월에는 챗GPT의 버그로 인해 사이트에서 한 활성 사용자의 채팅 기록 제목이 관련 없는 사용자에게 표시되는 현상이 발생한 바 있다. 이에 오픈AI는 챗GPT를 오프라인으로 전환했다.\n",
      "\n",
      "이러한 유형의 시스템 오류는 종종 발생할 수 있다. 정확한 원인은 인시던트마다 다르지만, 프론트엔드 디바이스와 백엔드 디바이스 사이에 있는 미들박스 디바이스와 관련된 경우가 많은 것으로 알려졌다.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"미들박스는 성능 향상을 위해 최근에 로그인한 사용자의 자격 증명을 비롯한 특정 데이터를 캐시하는 기능이다. 이때 불일치가 발생하면 한 계정의 정보를 다른 계정에 매핑하는 등의 문제가 발생할 수 있다. \n",
      "\n",
      "해당 논란과 관련해 오픈AI 담당자는 이번 사건에 대해 아직 조사하고 있다고 밝혔다.\n",
      "\n",
      "출처 : 디지털투데이 (DigitalToday)(https://www.digitaltoday.co.kr)\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\" AI리포터가 알린 주요 사례에 따르면, 챗GPT 챗봇이 사용자의 로그인 정보와 개인 정보를 유출했다는 주장이 제기되었으며 이에 대한 제보자의 비난이 이어졌다. 이는 AI 서비스에서 개인 정보를 최대한 배제해야 함을 상기시키는 사례로, 이전에도 유사한 버그로 인해 오픈AI가 챗GPT를 오프라인으로 전환한 적이 있었다. 이러한 시스템 오류는 종종 발생하지만, 주로 프론트엔드 디바이스와 백엔드 디바이스 사이에 있는 미들박스 디바이스와 관련된 것으로 알려져 있다. \n",
      "\n",
      "\n",
      "\"Middlebox is a feature that caches certain data, including credentials of recently logged-in users, to improve performance. However, this can cause issues such as mapping information between different accounts when inconsistencies arise. OpenAI is currently investigating this controversy, according to an official. Source: DigitalToday.\"\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' According to AI reporters, there have been claims of a GPT chatbot leaking user login and personal information, leading to backlash. This serves as a reminder for AI services to minimize personal information and cache data responsibly. OpenAI has previously encountered similar bugs and is currently investigating this issue.'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = TextLoader('./news.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=50)\n",
    "\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\", verbose=True)\n",
    "chain.run(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents\n",
    "\n",
    ": 에이전트는 체인이 사용할 도구(Tools)들을 지원하며 LLMs들이 원하는 작업을 수행하도록 절차를 정의할 수 있다.\n",
    "\n",
    "\n",
    "\n",
    "**Tools**  \n",
    "\n",
    "Agents들이 LLMs와 쉽게 상호 작용할 수 있도록 추상화한 기능. [Tools](https://python.langchain.com/docs/integrations/tools/) / [CustomAgent](https://python.langchain.com/docs/modules/agents/how_to/custom_agent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI\n",
    "import json\n",
    "import os\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "serpapi_api_key=os.getenv(\"SERP_API_KEY\", \"YourAPIKey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkit = load_tools([\"serpapi\"], llm=llm, serpapi_api_key=serpapi_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(toolkit, llm, agent=\"zero-shot-react-description\", verbose=True, return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should search for the first album of Big Bang\n",
      "Action: Search\n",
      "Action Input: Big Bang first album\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['Big Bang is V.I.P is the second single album by the South Korean boy band Big Bang, released by YG Entertainment on September 28, 2006. It spawned the single \"La La La\".', 'Big Bang Is V.I.P type: Album by BIGBANG.', 'Big Bang Is V.I.P artist: BIGBANG.', 'Big Bang Vol. 1 – Since 2007 is the debut studio album by South Korean boy band BigBang, released on December 22, 2006 through YG Entertainment.', 'The release of their debut album, BigBang Vol. 1 – Since 2007 (2006) followed. Debuting at no. 3, the album went on to sell over 110,000 copies.', 'BIGBANG* – First Single Album ; Have:20 ; Want:10 ; Avg Rating:4 / 5 ; Ratings:1 ; Last Sold:Never ...', 'BIGBANG - BIGBANG [First Single Album] 1st Single Album CD+etc+Tracking Number K-POP SEALED - Amazon.com Music.', '1. Big Bang (8) - Bigbang Vol.1 album cover. More images. Genre: Electronic, Hip ... Big Bang (8) - First Single Album. First Single Album · BIGBANG. Released.', 'Besides the Made singles, such as Bang Bang Bang, Loser, Bae Bae and \"Let\\'s Not Fall in Love,\" the album also features three new tracks, namely the double title ...', 'BIGBANG Vol.1 (also known as Since 2007) is the first Korean full-length album by BIGBANG. It was released on December 21, 2006 with \"Dirty Cash\" serving as ...', \"Number 1 is BIGBANG's first full-length Japanese album. It includes songs from their two previous mini-albums released in Japan. The song ...\", 'BIGBANG - [ALWAYS] 1st Mini Album. Release Date: August 17, 2007. Contents (per version):. 1 CD; 1 Photo Book. Depending on versions, contents (cover, ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should look for the release date of the first album\n",
      "Action: Search\n",
      "Action Input: Big Bang first album release date\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSeptember 28, 2006\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should confirm the title of the first album\n",
      "Action: Search\n",
      "Action Input: Big Bang first album title\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['BIGBANG/We Belong Together type: Album by BIGBANG.', 'Big Bang Vol. 1 – Since 2007 is the debut studio album by South Korean boy band BigBang, released on December 22, 2006 through YG Entertainment.', 'BIGBANG* – First Single Album ; Have:20 ; Want:10 ; Avg Rating:4 / 5 ; Ratings:1 ; Last Sold:Never ...', 'Big Bang is the debut single album by South Korean boy band Big Bang, released via YG Entertainment on August 28, 2006. It spawned the single \"We Belong ...', \"What is BIGBANG's debut? ... I used to consider We Belong Together as their debut song, because it is the title track of their first singl album ( ...\", '\"BIGBANG\" (also known as \"Bigbang First Single\") is the debut single album by BIGBANG. It was released on August 28, 2006 with \"We Belong Together\" serving ...', \"BIGBANG has released a teaser for “FXXK IT,” a song from the group's long-awaited “MADE” full album. The song will be released on December ...\", 'Bigbang Vol. 1 (also known as Since 2007) is the first Korean full-length album by BIGBANG. It was released on December 21, 2006 with \"Dirty Cash\" serving ...', 'BIGBANG - [ALWAYS] 1st Mini Album Release Date: August 17, 2007 Contents (per version): 1 CD 1 Photo Book Depending on versions, contents (cover, ...', \"Number 1 is BIGBANG's first full-length Japanese album. It includes songs from their two previous mini-albums released in Japan. The song ...\"]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should check for any other relevant information about the first album\n",
      "Action: Search\n",
      "Action Input: Big Bang first album information\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1 – Since 2007 is the debut studio album by South Korean boy band BigBang, released on December 22, 2006 through YG Entertainment. The album debuted at number three on the old monthly album charts in South Korea in December 2006, moving 33,000 units in its first month.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Big Bang Vol. 1 - Since 2007 is the first album of Big Bang, released on December 22, 2006.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent({\"input\":\"빅뱅의 첫번째 앨범은 무엇인가요?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"agent\",\n",
      "        \"AgentAction\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool\": \"Search\",\n",
      "        \"tool_input\": \"Big Bang first album\",\n",
      "        \"log\": \" I should search for the first album of Big Bang\\nAction: Search\\nAction Input: Big Bang first album\"\n",
      "      }\n",
      "    },\n",
      "    \"['Big Bang is V.I.P is the second single album by the South Korean boy band Big Bang, released by YG Entertainment on September 28, 2006. It spawned the single \\\"La La La\\\".', 'Big Bang Is V.I.P type: Album by BIGBANG.', 'Big Bang Is V.I.P artist: BIGBANG.', 'Big Bang Vol. 1 \\u2013 Since 2007 is the debut studio album by South Korean boy band BigBang, released on December 22, 2006 through YG Entertainment.', 'The release of their debut album, BigBang Vol. 1 \\u2013 Since 2007 (2006) followed. Debuting at no. 3, the album went on to sell over 110,000 copies.', 'BIGBANG* \\u2013 First Single Album ; Have:20 ; Want:10 ; Avg Rating:4 / 5 ; Ratings:1 ; Last Sold:Never ...', 'BIGBANG - BIGBANG [First Single Album] 1st Single Album CD+etc+Tracking Number K-POP SEALED - Amazon.com Music.', '1. Big Bang (8) - Bigbang Vol.1 album cover. More images. Genre: Electronic, Hip ... Big Bang (8) - First Single Album. First Single Album \\u00b7 BIGBANG. Released.', 'Besides the Made singles, such as Bang Bang Bang, Loser, Bae Bae and \\\"Let\\\\'s Not Fall in Love,\\\" the album also features three new tracks, namely the double title ...', 'BIGBANG Vol.1 (also known as Since 2007) is the first Korean full-length album by BIGBANG. It was released on December 21, 2006 with \\\"Dirty Cash\\\" serving as ...', \\\"Number 1 is BIGBANG's first full-length Japanese album. It includes songs from their two previous mini-albums released in Japan. The song ...\\\", 'BIGBANG - [ALWAYS] 1st Mini Album. Release Date: August 17, 2007. Contents (per version):. 1 CD; 1 Photo Book. Depending on versions, contents (cover, ...']\"\n",
      "  ],\n",
      "  [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"agent\",\n",
      "        \"AgentAction\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool\": \"Search\",\n",
      "        \"tool_input\": \"Big Bang first album release date\",\n",
      "        \"log\": \" I should look for the release date of the first album\\nAction: Search\\nAction Input: Big Bang first album release date\"\n",
      "      }\n",
      "    },\n",
      "    \"September 28, 2006\"\n",
      "  ],\n",
      "  [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"agent\",\n",
      "        \"AgentAction\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool\": \"Search\",\n",
      "        \"tool_input\": \"Big Bang first album title\",\n",
      "        \"log\": \" I should confirm the title of the first album\\nAction: Search\\nAction Input: Big Bang first album title\"\n",
      "      }\n",
      "    },\n",
      "    \"['BIGBANG/We Belong Together type: Album by BIGBANG.', 'Big Bang Vol. 1 \\u2013 Since 2007 is the debut studio album by South Korean boy band BigBang, released on December 22, 2006 through YG Entertainment.', 'BIGBANG* \\u2013 First Single Album ; Have:20 ; Want:10 ; Avg Rating:4 / 5 ; Ratings:1 ; Last Sold:Never ...', 'Big Bang is the debut single album by South Korean boy band Big Bang, released via YG Entertainment on August 28, 2006. It spawned the single \\\"We Belong ...', \\\"What is BIGBANG's debut? ... I used to consider We Belong Together as their debut song, because it is the title track of their first singl album ( ...\\\", '\\\"BIGBANG\\\" (also known as \\\"Bigbang First Single\\\") is the debut single album by BIGBANG. It was released on August 28, 2006 with \\\"We Belong Together\\\" serving ...', \\\"BIGBANG has released a teaser for \\u201cFXXK IT,\\u201d a song from the group's long-awaited \\u201cMADE\\u201d full album. The song will be released on December ...\\\", 'Bigbang Vol. 1 (also known as Since 2007) is the first Korean full-length album by BIGBANG. It was released on December 21, 2006 with \\\"Dirty Cash\\\" serving ...', 'BIGBANG - [ALWAYS] 1st Mini Album Release Date: August 17, 2007 Contents (per version): 1 CD 1 Photo Book Depending on versions, contents (cover, ...', \\\"Number 1 is BIGBANG's first full-length Japanese album. It includes songs from their two previous mini-albums released in Japan. The song ...\\\"]\"\n",
      "  ],\n",
      "  [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"agent\",\n",
      "        \"AgentAction\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"tool\": \"Search\",\n",
      "        \"tool_input\": \"Big Bang first album information\",\n",
      "        \"log\": \" I should check for any other relevant information about the first album\\nAction: Search\\nAction Input: Big Bang first album information\"\n",
      "      }\n",
      "    },\n",
      "    \"1 \\u2013 Since 2007 is the debut studio album by South Korean boy band BigBang, released on December 22, 2006 through YG Entertainment. The album debuted at number three on the old monthly album charts in South Korea in December 2006, moving 33,000 units in its first month.\"\n",
      "  ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from langchain.load.dump import dumps\n",
    "\n",
    "print(dumps(response[\"intermediate_steps\"], pretty=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
